{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syllable conditioned GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartModel,BartForConditionalGeneration\n",
    "from torch.distributions import Categorical\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from undecorated import undecorated\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from transformers import  Seq2SeqTrainingArguments, Seq2SeqTrainer,DataCollatorForSeq2Seq\n",
    "metric = load_metric(\"rouge\")\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import types\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions import Categorical\n",
    "import random\n",
    "#from torch.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_utils import get_end_mask,get_valid_mask,Discriminator,discriminator_train_standard, generate_random_input_syllables,reinforce_loss_syllables,Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import PoemDataset,encode_sentences_wsyl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "#generator = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct syllable dictionary\n",
    "\n",
    "\n",
    "every random input will have syllables 5-7-5 (+1,0) (some noise so discriminator hopefully wont learn just this, and because real data has some noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here im making a dictionary of all tokens and their associated syllable count\n",
    "from nltk.tokenize import SyllableTokenizer\n",
    "syllable_dict = {}\n",
    "for token in range(50265):\n",
    "    syl_tokenizer = SyllableTokenizer()\n",
    "    t = torch.tensor(token)\n",
    "    #print(tokenizer.decode(t),len(syl_tokenizer.tokenize(tokenizer.decode(t).strip())))\n",
    "    syllable_dict[token] = len(syl_tokenizer.tokenize(tokenizer.decode(t).strip()))\n",
    "syllable_dict[0] = 0\n",
    "syllable_dict[2] = 0\n",
    "syllable_dict[1] = 0\n",
    "syllable_dict[50118] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(logprob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = Generator().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_vec(row):\n",
    "    return [row['line_0_scount'],row['line_1_scount'],row['line_2_scount']]\n",
    "\n",
    "def change_title(row):\n",
    "    #adds syllable info to title\n",
    "    #print(row['Title'])\n",
    "    return str(row['syllables']) + ';' + str(row['Title'])\n",
    "\n",
    "def add_syllables_title(part_df, match_df):\n",
    "    merged = pd.merge(part_df, match_df,how='left', left_on=['Unnamed: 0'], right_index=True)\n",
    "    merged['syllables'] = merged.apply(syllable_vec,axis=1)\n",
    "    merged.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y','line_0','line_1','line_2','source','valid','line_0_scount',\n",
    "                        'line_1_scount','line_2_scount'],inplace=True)\n",
    "    merged['Title'] = merged.apply(change_title,axis=1)\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir =  '/home/alexander/nlg-project/data/'\n",
    "test_df = pd.read_csv(processed_data_dir + 'test_data.csv')\n",
    "train_df = pd.read_csv(processed_data_dir + 'train_data.csv')\n",
    "whole_df = pd.read_csv(processed_data_dir + 'kaggle_data.csv')\n",
    "\n",
    "\n",
    "train_df = add_syllables_title(train_df,whole_df)\n",
    "test_df = add_syllables_title(test_df,whole_df)\n",
    "\n",
    "test_model = encode_sentences_wsyl(tokenizer,test_df)\n",
    "\n",
    "\n",
    "train_model = encode_sentences_wsyl(tokenizer,train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoemDataset_syl(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = df['labels']\n",
    "        self.mask = df['attention_mask']\n",
    "        self.input = df['input_ids']\n",
    "        self.syllables = df['syllables']\n",
    "        #self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        input_ids = self.input[idx]\n",
    "        attention_masks = self.mask[idx]\n",
    "        target_ids = self.labels[idx]\n",
    "        syllables = self.syllables[idx]\n",
    "        batch = {\n",
    "          \"input_ids\": input_ids,\n",
    "          \"decoder_attention_mask\": torch.tensor([1] * 128),\n",
    "          \"attention_mask\": attention_masks,\n",
    "          \"label_ids\": target_ids,\n",
    "          \"syllables\":syllables\n",
    "        }\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PoemDataset_syl(train_model)\n",
    "eval_ds = PoemDataset_syl(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator = discriminator.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/alexander/nlg-project/GAN_models_syllables/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #reduced to a binary problem \n",
    "bsize = 12\n",
    "generator =  Generator().cuda()#BartForConditionalGeneration.from_pretrained('facebook/bart-base').cuda()\n",
    "#model = TheModelClass(*args, **kwargs)\n",
    "#generator.load_state_dict(torch.load(PATH + 'generator.pt')['model_state_dict'])\n",
    "discriminator = Discriminator().cuda()\n",
    "discriminator.load_state_dict(torch.load(PATH + 'discriminator.pt')['model_state_dict'])\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = generate_random_input_syllables(bsize,'cuda')\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "ewma_reward = 0.0#torch.tensor(0.0)\n",
    "fake_label = 0.\n",
    "lr = .000001\n",
    "beta1 = .9\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=lr*.05, betas=(beta1, 0.99)) \n",
    "optimizerG = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample losses towards end of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8925a490d0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(G_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efff10eb1c0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(D_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"G_losses_5_5_syl.txt\", \"w\") as f:\n",
    "    for s in G_losses:\n",
    "        f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "Label Noise: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-2ea912393255>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output_tokens = torch.cat([output_tokens,torch.tensor(next_word).unsqueeze(1)],axis=1)\n",
      "/home/alexander/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "<ipython-input-17-0f424487d694>:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  syl_diff = torch.tensor(desired_syllables - running_syllables,dtype=torch.int32).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disc LogProbs True\n",
      "tensor([[3.8895, 3.7554, 3.9745, 4.2929, 4.0554, 4.7351, 4.8642, 4.9528, 4.9829,\n",
      "         4.9843, 4.9728, 5.0016, 5.0026, 5.1074, 5.0888, 5.0904, 5.1139, 5.1421,\n",
      "         5.1209, 5.1313, 5.0131]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Disc LogProbs False\n",
      "tensor([[ 1.3536,  1.1512,  0.0761, -0.1045, -0.7076, -0.8751, -0.6863, -1.2499]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "gen loss\n",
      "tensor([[ 2.7256e-02,  1.0229e-02,  2.6341e-03,  2.1473e-03, -1.0808e-03,\n",
      "         -1.3198e-02,  4.3744e-02,  2.1865e-06]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "cum rewards\n",
      "tensor([[ 0.5894,  0.6753,  0.0528, -0.0739, -0.4841, -0.5876,  0.5283,  0.3745]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "gen logprobs\n",
      "tensor([[-3.4585e-02, -1.1703e-02, -1.0473e-02, -1.7218e-02, -3.7861e-03,\n",
      "         -3.3934e-02, -6.0177e-02, -3.8147e-06]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "[' mother thanks yourself from this day that</s>']\n",
      "[0/30][0/11403]\tLoss_D: 4.9405\tLoss_G: -0.0017\tD(x): 3.5198\tD(G(z)): -0.4202 / -0.0017\n",
      "['</s><s> they, that i</s>', '</s><s> they, that i</s>']\n",
      "[0/30][256/11403]\tLoss_D: 4.4134\tLoss_G: -0.0607\tD(x): 3.4454\tD(G(z)): -0.6727 / -0.0607\n",
      "[0/30][512/11403]\tLoss_D: 8.6408\tLoss_G: -0.2113\tD(x): 1.8012\tD(G(z)): -0.7121 / -0.2113\n",
      "[0/30][768/11403]\tLoss_D: 9.6159\tLoss_G: 0.0368\tD(x): 2.5778\tD(G(z)): -0.3711 / 0.0368\n",
      "['</s><s> they, that i</s><pad>', '</s><s> they, that i</s><pad>']\n",
      "saving geneartor\n",
      "[0/30][1024/11403]\tLoss_D: 2.2648\tLoss_G: -0.0182\tD(x): 2.3209\tD(G(z)): -4.4783 / -0.0182\n",
      "[0/30][1280/11403]\tLoss_D: 5.0865\tLoss_G: -0.1662\tD(x): 3.6788\tD(G(z)): -0.5034 / -0.1662\n",
      "[0/30][1536/11403]\tLoss_D: 9.6626\tLoss_G: -0.0083\tD(x): 2.6618\tD(G(z)): -0.7340 / -0.0083\n",
      "[0/30][1792/11403]\tLoss_D: 12.6576\tLoss_G: -0.3795\tD(x): 1.8106\tD(G(z)): -0.5583 / -0.3795\n",
      "['</s><s> blue balls, which was</s>', '</s><s> blue balls, which was</s>']\n",
      "saving geneartor\n",
      "[0/30][2048/11403]\tLoss_D: 3.2739\tLoss_G: -0.1633\tD(x): 2.2403\tD(G(z)): -4.9852 / -0.1633\n",
      "[0/30][2304/11403]\tLoss_D: 1.6838\tLoss_G: -0.0299\tD(x): 3.4836\tD(G(z)): -4.9845 / -0.0299\n",
      "[0/30][2560/11403]\tLoss_D: 5.2107\tLoss_G: -0.0738\tD(x): 3.0408\tD(G(z)): -0.6098 / -0.0738\n",
      "[0/30][2816/11403]\tLoss_D: 7.7698\tLoss_G: 0.0448\tD(x): 1.7901\tD(G(z)): -0.2205 / 0.0448\n",
      "['</s><s> they, day that was</s>', '</s><s> they, day that was</s>']\n",
      "saving geneartor\n",
      "[0/30][3072/11403]\tLoss_D: 1.3771\tLoss_G: 0.0634\tD(x): 3.4635\tD(G(z)): -5.1928 / 0.0634\n",
      "[0/30][3328/11403]\tLoss_D: 5.5069\tLoss_G: -0.0616\tD(x): 2.7728\tD(G(z)): -0.5305 / -0.0616\n",
      "[0/30][3584/11403]\tLoss_D: 4.4579\tLoss_G: 0.2493\tD(x): 2.8800\tD(G(z)): -0.9586 / 0.2493\n",
      "[0/30][3840/11403]\tLoss_D: 7.2879\tLoss_G: 0.1122\tD(x): 2.2000\tD(G(z)): -0.4259 / 0.1122\n",
      "['</s><s> they, day was when</s>', '</s><s> they, day that was</s>']\n",
      "saving geneartor\n",
      "Disc LogProbs True\n",
      "tensor([[ 0.4609,  1.0974,  0.3512, -0.3575,  4.2219,  4.1947,  4.2610,  4.2107,\n",
      "          4.2427,  4.2598,  4.2173,  4.1398,  4.2199,  4.2154,  4.2878,  4.3069,\n",
      "          4.3028,  4.2512,  4.2614]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Disc LogProbs False\n",
      "tensor([[ 0.1223, -1.6576, -1.6811, -1.8749, -1.9184, -2.0613, -2.0249, -1.8792,\n",
      "         -1.9527, -1.9687, -0.0000, -0.0000, -0.0000]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "gen loss\n",
      "tensor([[ 8.4268e+00,  1.1754e-01, -1.0675e-01, -1.1696e-01,  5.3381e-01,\n",
      "         -1.7279e+00, -5.8779e-01, -1.5121e+00, -4.0613e+00, -8.5161e-06,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "cum rewards\n",
      "tensor([[ 0.0611, -0.8838, -0.9537, -1.0402, -0.0602, -1.2051, -1.2952, -1.3500,\n",
      "         -1.4735, -1.3118,  0.0000,  0.0000,  0.0000]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "gen logprobs\n",
      "tensor([[-8.4200e+00, -2.1006e+00, -7.6599e+00, -1.1649e+00, -6.0690e-01,\n",
      "         -6.5106e+00, -1.6538e+00, -3.6861e+00, -7.6084e+00, -2.2888e-05,\n",
      "         -2.2003e+01, -3.7528e+01, -3.7274e+01]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "[' well good eyes when the shock was back.</s><pad><pad><pad>']\n",
      "[0/30][4096/11403]\tLoss_D: 4.0689\tLoss_G: 0.1768\tD(x): 3.1968\tD(G(z)): -1.3870 / 0.1768\n",
      "[0/30][4352/11403]\tLoss_D: 4.2387\tLoss_G: 0.0453\tD(x): 3.0655\tD(G(z)): -1.2481 / 0.0453\n",
      "[0/30][4608/11403]\tLoss_D: 4.7531\tLoss_G: -0.2141\tD(x): 1.2318\tD(G(z)): -4.4737 / -0.2141\n",
      "[0/30][4864/11403]\tLoss_D: 1.2522\tLoss_G: -0.0431\tD(x): 3.6887\tD(G(z)): -4.8750 / -0.0431\n",
      "['</s><s> they, day that was</s>', '</s><s> they, day that was</s>']\n",
      "saving geneartor\n",
      "[0/30][5120/11403]\tLoss_D: 3.2850\tLoss_G: 0.0996\tD(x): 2.8565\tD(G(z)): -0.9827 / 0.0996\n",
      "[0/30][5376/11403]\tLoss_D: 6.8586\tLoss_G: 0.0181\tD(x): 2.5611\tD(G(z)): -0.5592 / 0.0181\n",
      "[0/30][5632/11403]\tLoss_D: 5.7062\tLoss_G: 0.1396\tD(x): 3.2924\tD(G(z)): -0.7450 / 0.1396\n",
      "[0/30][5888/11403]\tLoss_D: 2.4585\tLoss_G: 0.0374\tD(x): 2.5170\tD(G(z)): -4.8795 / 0.0374\n",
      "['</s><s> they, that green of</s>', '</s><s> they, that green of</s>']\n",
      "saving geneartor\n",
      "[0/30][6144/11403]\tLoss_D: 4.3883\tLoss_G: 0.0033\tD(x): 1.8985\tD(G(z)): -5.1295 / 0.0033\n",
      "[0/30][6400/11403]\tLoss_D: 1.7169\tLoss_G: 0.2019\tD(x): 3.4161\tD(G(z)): -4.6032 / 0.2019\n",
      "[0/30][6656/11403]\tLoss_D: 1.5843\tLoss_G: -0.0732\tD(x): 1.9626\tD(G(z)): -5.3224 / -0.0732\n",
      "[0/30][6912/11403]\tLoss_D: 1.8474\tLoss_G: 0.0223\tD(x): 3.1815\tD(G(z)): -5.0637 / 0.0223\n",
      "['</s><s> they, that green of</s>', '</s><s> they, that green of</s>']\n",
      "saving geneartor\n",
      "[0/30][7168/11403]\tLoss_D: 2.4323\tLoss_G: -0.1477\tD(x): 3.0911\tD(G(z)): -5.0393 / -0.1477\n",
      "[0/30][7424/11403]\tLoss_D: 9.8141\tLoss_G: 0.3297\tD(x): 2.6878\tD(G(z)): -0.1949 / 0.3297\n",
      "[0/30][7680/11403]\tLoss_D: 7.0199\tLoss_G: 0.0765\tD(x): 1.8427\tD(G(z)): -0.6764 / 0.0765\n",
      "[0/30][7936/11403]\tLoss_D: 7.8258\tLoss_G: -0.0304\tD(x): 2.4170\tD(G(z)): -0.3032 / -0.0304\n",
      "['</s><s> they, that green of</s>', '</s><s> they, that green of</s>']\n",
      "saving geneartor\n",
      "Disc LogProbs True\n",
      "tensor([[ 0.5811, -0.0741, -0.4769, -0.8467, -0.8165, -0.7673, -0.8171, -0.8618,\n",
      "         -0.9357,  5.1368,  5.2144,  5.2153,  5.2133,  5.2093,  5.3015,  5.2900,\n",
      "          5.3014,  5.3072,  5.3018,  5.3140,  5.3079,  5.1752]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Disc LogProbs False\n",
      "tensor([[-3.6429, -3.0774, -4.3606, -4.9807, -5.4111, -5.4928, -5.7498]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "gen loss\n",
      "tensor([[ 1.0642,  0.0089,  0.0072, -0.7021, -0.7143, -0.1124,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "cum rewards\n",
      "tensor([[-0.9490, -1.1855, -0.3549, -1.4977, -1.7124, -1.8158, -1.6525]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "gen logprobs\n",
      "tensor([[-2.7829, -0.0607, -0.0074, -4.2227, -1.8747, -0.2321,  0.0000]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "[' got terrible people enverry black</s>']\n",
      "[0/30][8192/11403]\tLoss_D: 2.6764\tLoss_G: -0.2146\tD(x): 3.0413\tD(G(z)): -4.6859 / -0.2146\n",
      "[0/30][8448/11403]\tLoss_D: 5.0336\tLoss_G: -0.0180\tD(x): 3.5473\tD(G(z)): -0.6596 / -0.0180\n",
      "[0/30][8704/11403]\tLoss_D: 1.5982\tLoss_G: -0.0738\tD(x): 1.9825\tD(G(z)): -4.7874 / -0.0738\n",
      "[0/30][8960/11403]\tLoss_D: 8.6603\tLoss_G: -0.1531\tD(x): 3.1946\tD(G(z)): 0.1894 / -0.1531\n",
      "['</s><s> they, that green of</s>', '</s><s> they, green ofvor</s>']\n",
      "saving geneartor\n",
      "[0/30][9216/11403]\tLoss_D: 7.6510\tLoss_G: 0.0074\tD(x): 1.6308\tD(G(z)): -0.1874 / 0.0074\n",
      "[0/30][9472/11403]\tLoss_D: 5.1827\tLoss_G: 0.0654\tD(x): 2.4961\tD(G(z)): -0.8277 / 0.0654\n",
      "[0/30][9728/11403]\tLoss_D: 5.5944\tLoss_G: -0.1545\tD(x): 2.5113\tD(G(z)): -0.7203 / -0.1545\n",
      "[0/30][9984/11403]\tLoss_D: 4.1561\tLoss_G: -0.0041\tD(x): 2.0957\tD(G(z)): -0.9107 / -0.0041\n",
      "['</s><s> they, that green of</s>', '</s><s> they, that green of</s>']\n",
      "saving geneartor\n",
      "[0/30][10240/11403]\tLoss_D: 4.3265\tLoss_G: 0.1569\tD(x): 2.6555\tD(G(z)): -1.0967 / 0.1569\n",
      "[0/30][10496/11403]\tLoss_D: 1.6474\tLoss_G: -0.1026\tD(x): 3.6986\tD(G(z)): -3.7072 / -0.1026\n",
      "[0/30][10752/11403]\tLoss_D: 1.8674\tLoss_G: -0.0982\tD(x): 3.4624\tD(G(z)): -4.6832 / -0.0982\n",
      "['</s><s> they, that i of</s>', '</s><s> they, that i of</s>']\n",
      "saving geneartor\n",
      "[0/30][11008/11403]\tLoss_D: 5.7490\tLoss_G: 0.2661\tD(x): 1.9831\tD(G(z)): -0.5740 / 0.2661\n",
      "[0/30][11264/11403]\tLoss_D: 3.9274\tLoss_G: 0.0493\tD(x): 3.7014\tD(G(z)): -0.8310 / 0.0493\n",
      "Label Noise: 0.045000000000000005\n",
      "Disc LogProbs True\n",
      "tensor([[4.0600, 3.8477, 4.1543, 4.7122, 4.5271, 4.9459, 5.0118, 5.0374, 5.0647,\n",
      "         5.0770, 5.1104, 5.1107, 5.1166, 5.1906, 5.1692, 5.2019, 5.2095, 5.2293,\n",
      "         5.2382, 5.2137, 5.1696]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "Disc LogProbs False\n",
      "tensor([[-5.7796, -5.5975, -4.9205, -5.2463, -5.3972, -5.5641, -5.6295]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "gen loss\n",
      "tensor([[ 2.8264e-05, -4.2871e-05, -1.0802e-04, -1.7393e-03, -1.8234e+00,\n",
      "         -2.8867e-03, -2.5920e-05]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "cum rewards\n",
      "tensor([[ 0.0062, -1.3904, -1.5699, -1.7022, -1.8122, -1.9166, -1.7514]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>)\n",
      "gen logprobs\n",
      "tensor([[-2.2888e-05, -2.6512e-04, -3.1662e-04, -3.6736e-03, -3.1247e+00,\n",
      "         -4.1962e-03, -4.9591e-05]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "[' interrogated they, that I that</s>']\n",
      "[1/30][0/11403]\tLoss_D: 1.2336\tLoss_G: -0.0251\tD(x): 3.5385\tD(G(z)): -4.5263 / -0.0251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30][256/11403]\tLoss_D: 2.9765\tLoss_G: -0.0567\tD(x): 3.2158\tD(G(z)): -3.2815 / -0.0567\n",
      "[1/30][512/11403]\tLoss_D: 2.4729\tLoss_G: -0.0071\tD(x): 1.7732\tD(G(z)): -4.4836 / -0.0071\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "device = 'cuda'\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "num_epochs = 30\n",
    "\n",
    "train_dl = DataLoader(train_ds,batch_size=bsize,num_workers=2)\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Label Noise:\",0.05*.9**epoch)\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "       # print(i)\n",
    "        \n",
    "        if len(data['input_ids']) < bsize:\n",
    "            continue\n",
    "       # print(data)\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        \n",
    "        # Format batch\n",
    "        real_inputs = data['input_ids'].to(device)\n",
    "        real_input_attention = data['attention_mask'].to(device)\n",
    "        real_input_test = {'input_ids':real_inputs,'attention_mask':real_input_attention}\n",
    "        \n",
    "        \n",
    "        real_gpu = data['label_ids'].to(device)\n",
    "        attention_gpu = data['decoder_attention_mask'].to(device)\n",
    "        b_size = real_gpu.size(0)\n",
    "        #\n",
    "        label = torch.full((b_size,), 1.0 , dtype=torch.float, device=device) #.95 instead of real to inject noise\n",
    "        label = torch.bernoulli(label)\n",
    "       # print(label)\n",
    "        # Forward pass real batch through D\n",
    "        real_mask = get_valid_mask(real_gpu)\n",
    "\n",
    "        output_real,loss_real = discriminator_train_standard(discriminator,real_gpu[:,1:],label,criterion,mask=real_mask)\n",
    "\n",
    "        loss_real.backward()\n",
    "\n",
    "        #del label\n",
    "        #output = discriminator(real_gpu,attention_mask=attention_gpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        #errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        #errD_real.backward()\n",
    "        D_x = output_real.detach().mean().item()\n",
    "        #del output_real\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise,noise_syl = generate_random_input_syllables(bsize,device)#torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        #print(fake)\n",
    "       # print(noise)\n",
    "        if random.random() > .5:\n",
    "            titles = noise['input_ids']\n",
    "            syllables = noise_syl\n",
    "            fake,fake_logprobs = generator(noise)\n",
    "        else:\n",
    "            titles = real_input_test['input_ids']\n",
    "            syllables = data['syllables']\n",
    "            #sometimes the discirminator learns words in real input, this way some will be based on these same words\n",
    "            fake,fake_logprobs = generator(real_input_test)\n",
    "            #real_input_test\n",
    "\n",
    "        fake_mask = get_valid_mask(fake)\n",
    "        end_mask = get_end_mask(fake)\n",
    "  \n",
    "        #generate_sequence(generator,noise)\n",
    "       # print(len(fake_logprobs))\n",
    "        #a = 1/0\n",
    "        #fake = generator.generate_with_grad(noise['input_ids'].cuda(),attention_mask=noise[\"attention_mask\"].cuda()) #,max_length=128\n",
    "       # print(fake)\n",
    "        #print((fake.logits))\n",
    "        #fake = decode(fake.logits)\n",
    "      #  print(fake)\n",
    "        # I am injecting some false positives into the fake labels so the discriminator does a worse job\n",
    "        label.fill_(0.0) \n",
    "        label = torch.bernoulli(label)\n",
    "       # print(label)\n",
    "        # Classify all fake batch with D\n",
    "        output_fake,loss_fake = discriminator_train_standard(discriminator,fake,label,criterion,mask=fake_mask)\n",
    "\n",
    "        loss_fake.backward()\n",
    "       # print('fake')\n",
    "       # print(loss_fake.detach())\n",
    "        #output = discriminator(fake).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        #errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "       # errD_fake.backward()\n",
    "        D_G_z1 = output_fake.detach().cpu().mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = (torch.mean(loss_real.detach()) + torch.mean(loss_fake.detach())).cpu()\n",
    "       # del output_real\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "        \n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        \n",
    "\n",
    "\n",
    "        lossG, cumulative_rewards, ewma_reward = reinforce_loss_syllables(output_fake,fake_logprobs,.3,.08,epoch,fake_mask,end_mask,syllables,fake,ewma_reward,syllable_dict)\n",
    "        if i % (1024*4) == 0:\n",
    "            print('Disc LogProbs True')\n",
    "            print(output_real[0:1])\n",
    "            print('Disc LogProbs False')\n",
    "            print(output_fake[0:1])\n",
    "            print('gen loss')\n",
    "            print(lossG[0:1])\n",
    "            print('cum rewards')\n",
    "            print(cumulative_rewards[0:1])\n",
    "            print('gen logprobs')\n",
    "            print(fake_logprobs[0:1])\n",
    "            print(tokenizer.batch_decode(fake[0:1].cpu()))\n",
    "\n",
    "        #print(lossG)\n",
    "        lossG = torch.mean(lossG)\n",
    "       # print(lossG)\n",
    "        #print(loss)\n",
    "        #label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "       # print(fake)\n",
    "        #output = discriminator(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        #errG = criterion(output, label)\n",
    "        #print(errG)\n",
    "        #errG = loss.detach()\n",
    "        # Calculate gradients for G\n",
    "        lossG.backward()\n",
    "        D_G_z2 = lossG.detach().cpu().mean().item()\n",
    "        # Update G\n",
    "        \n",
    "        optimizerG.step()\n",
    "        generator.zero_grad()\n",
    "        discriminator.zero_grad()\n",
    "        #a = 1/0\n",
    "        # Output training stats\n",
    "        if i % 256 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(train_dl),\n",
    "                     errD.item(), lossG.item(), D_x, D_G_z1, D_G_z2))\n",
    "          #  print('ewma_reward:',ewma_reward)\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(lossG.detach().item())\n",
    "        D_losses.append(errD.detach().item())\n",
    "        \n",
    "        del lossG\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 1000 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = tokenizer.batch_decode(generator.model.generate(fixed_noise[0]['input_ids'],attention_mask=fixed_noise[0][\"attention_mask\"],max_length=32,num_beams= 50,early_stopping = True))\n",
    "                print(fake[0:2])\n",
    "        if (iters % 1000 == 0 and iters != 0):\n",
    "            print('saving geneartor')\n",
    "            torch.save({\n",
    "            'epoch': 15,\n",
    "            'model_state_dict': generator.state_dict(),\n",
    "            'optimizer_state_dict': optimizerG.state_dict(),\n",
    "            'loss': 0.3355,\n",
    "            }, PATH + 'generator.pt')\n",
    "            torch.save({\n",
    "            'epoch': 15,\n",
    "            'model_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_state_dict': optimizerD.state_dict(),\n",
    "            'loss': 0.3355,\n",
    "            }, PATH + 'discriminator.pt')\n",
    "            #img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# del optimizerG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 15,\n",
    "            'model_state_dict': generator.state_dict(),\n",
    "            'optimizer_state_dict': optimizerG.state_dict(),\n",
    "            'loss': 0.3355,\n",
    "            }, PATH + '5_it_syl_generator.pt')\n",
    "torch.save({\n",
    "            'epoch': 15,\n",
    "            'model_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_state_dict': optimizerD.state_dict(),\n",
    "            'loss': 0.3355,\n",
    "            }, PATH + '5_it_syl_discriminator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"cats\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated (<ipython-input-35-f3e261162407>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-f3e261162407>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    max_length=16))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated\n"
     ]
    }
   ],
   "source": [
    "tokenizer.batch_decode(test_generator.model.eval().cpu().generate(inputs['input_ids'],attention_mask=inputs[\"attention_mask\"],max_length=128, use_cache=True,\n",
    "        decoder_start_token_id = tokenizer.pad_token_id,\n",
    "        num_beams= 50,\n",
    "        early_stopping = True, max_length=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"echidna\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(BartForConditionalGeneration.from_pretrained('BART-base/checkpoint-25000').eval().cpu().generate(inputs['input_ids'],attention_mask=inputs[\"attention_mask\"],max_length=128, use_cache=True,\n",
    "        decoder_start_token_id = tokenizer.pad_token_id,                 \n",
    "        num_beams= 50,\n",
    "        early_stopping = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 \n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    \"BART-base\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    #learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "   # weight_decay=0.01,\n",
    "   # save_total_limit=3,\n",
    "   # num_train_epochs=1,\n",
    "   # predict_with_generate=True,\n",
    "    \n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.999,\n",
    "    adam_epsilon=1e-6,\n",
    "    max_grad_norm=1.0,\n",
    "    num_train_epochs=10,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.1,\n",
    "   # label_names=\"labels\",\n",
    "    #fp16=True,\n",
    "  #  use_auth_token=False\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds = PoemDataset(model_input)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=BartForConditionalGeneration.from_pretrained('BART-base/checkpoint-25000'),\n",
    "    args=args,\n",
    "   # data_collator=data_collator,\n",
    "    train_dataset=train_ds,\n",
    "    \n",
    "    eval_dataset=eval_ds,\n",
    "    #use_auth_token=False,\n",
    "    \n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir GAN_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 15,\n",
    "            'model_state_dict': generator.state_dict(),\n",
    "            'optimizer_state_dict': optimizerG.state_dict(),\n",
    "            'loss': 0.3355,\n",
    "            }, PATH + 'generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 15,\n",
    "            'model_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_state_dict': optimizerD.state_dict(),\n",
    "            'loss': 0.3355,\n",
    "            }, PATH + 'discriminator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd GAN_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
