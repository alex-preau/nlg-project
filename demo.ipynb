{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos of Poem Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartModel,BartForConditionalGeneration\n",
    "from torch.distributions import Categorical\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from undecorated import undecorated\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from transformers import  Seq2SeqTrainingArguments, Seq2SeqTrainer,DataCollatorForSeq2Seq\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import types\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions import Categorical\n",
    "import random\n",
    "from collections import Counter\n",
    "from nltk.tokenize import SyllableTokenizer\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_utils import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import PoemDataset,encode_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuned GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_gan =  Generator()#BartForConditionalGeneration.from_pretrained('facebook/bart-base').cuda()\n",
    "#model = TheModelClass(*args, **kwargs)\n",
    "fine_tuned_gan.load_state_dict(torch.load('/home/alexander/nlg-project/GAN_models_finetuned/' + 'four_it_ft_generator_bad.pt')['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"help\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad><s> need to study\\nand return the power\\nof my day</s>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(fine_tuned_gan.model.eval().cpu().generate(inputs['input_ids'],attention_mask=inputs[\"attention_mask\"],max_length=32, use_cache=True,\n",
    "        decoder_start_token_id = tokenizer.pad_token_id,\n",
    "        num_beams= 100,\n",
    "        early_stopping = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "naive_gan =  Generator()\n",
    "naive_gan.load_state_dict(torch.load('/home/alexander/nlg-project/GAN_models/' + '6_it_nft_generator.pt')['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"help\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<pad><s>'s the romantic of a whore\\nthis summer whenever you have a\\nthis financial system of societies that would have you if I had to settle for</s>\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(naive_gan.model.eval().cpu().generate(inputs['input_ids'],attention_mask=inputs[\"attention_mask\"],max_length=32, use_cache=True,\n",
    "        decoder_start_token_id = tokenizer.pad_token_id,\n",
    "        num_beams= 100,\n",
    "        early_stopping = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syllable GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I accidenlty overwrote the better trained model during testing, this is a very early and poor performing model\n",
    "syllable_gan =  Generator().cuda()\n",
    "syllable_gan.load_state_dict(torch.load('GAN_models_syllables/' + '1_it_syl_generator.pt')['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_syl = tokenizer(\"[5,7,5];help\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad><s>prolo pro feelStunUn pro proSeTrans un pro get get get un</s>']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(syllable_gan.model.eval().cpu().generate(inputs_syl['input_ids'],attention_mask=inputs_syl[\"attention_mask\"],max_length=32, use_cache=True,\n",
    "        decoder_start_token_id = tokenizer.pad_token_id,\n",
    "        num_beams= 100,\n",
    "        early_stopping = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_gan =  Generator().cuda()\n",
    "title_gan.load_state_dict(torch.load('/home/alexander/nlg-project/GAN_models/' + 'final_gen_cond_title_generator.pt')['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad><s>T markets markets markets market</s>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(title_gan.model.eval().cpu().generate(inputs['input_ids'],attention_mask=inputs[\"attention_mask\"],max_length=32, use_cache=True,\n",
    "        decoder_start_token_id = tokenizer.pad_token_id,\n",
    "        num_beams= 100,\n",
    "        early_stopping = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BART Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_baseline = BartForConditionalGeneration.from_pretrained('/home/alexander/nlg-project/BART-base/' + 'checkpoint-25000')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad><s> you should be writing\\nlike a selfhelp book in love\\nwith a self love book</s>']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(bart_baseline.eval().cpu().generate(inputs['input_ids'],attention_mask=inputs[\"attention_mask\"],max_length=32, use_cache=True,\n",
    "        decoder_start_token_id = tokenizer.pad_token_id,\n",
    "        num_beams= 100,\n",
    "        early_stopping = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bart syllable aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_syl_aware = BartForConditionalGeneration.from_pretrained('/home/alexander/nlg-project/BART-base-syllable-naive/' + 'checkpoint-32000')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_syl = tokenizer(\"[5,7,5];help\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad><s> i dont understand\\nwhy people try to help me\\nwhen i cant help it</s>']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(bart_syl_aware.eval().cpu().generate(inputs_syl['input_ids'],attention_mask=inputs_syl[\"attention_mask\"],max_length=32, use_cache=True,\n",
    "        decoder_start_token_id = tokenizer.pad_token_id,\n",
    "        num_beams= 100,\n",
    "        early_stopping = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BART syllable loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_syl_loss = BartForConditionalGeneration.from_pretrained('/home/alexander/nlg-project/BART-base-syllable-loss/' + 'checkpoint-34000')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad><s> i really wanna\\nhelp people but i dont know\\nhow to help a lot</s>']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(bart_syl_loss.eval().cpu().generate(inputs_syl['input_ids'],attention_mask=inputs_syl[\"attention_mask\"],max_length=32, use_cache=True,\n",
    "        decoder_start_token_id = tokenizer.pad_token_id,\n",
    "        num_beams= 100,\n",
    "        early_stopping = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
